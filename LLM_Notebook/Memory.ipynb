{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Sentinel: ChatCompletionMessage(content=\"Yes, the fact that the person has knee pain and cannot do exercise should be saved in the long-term memory. This information can be useful for understanding the person's physical limitations and planning appropriate activities or recommendations in the future.\", role='assistant', function_call=None, tool_calls=None)\n",
      "ChatCompletionMessage(content='The fitness trainer could reply:\\n\"I recommend consulting with a medical professional to properly address and treat your knee pain. In the meantime, low-impact exercises such as swimming, cycling, or yoga may be more suitable for you. It\\'s important to listen to your body and not push through pain to avoid further injury.\"', role='assistant', function_call=None, tool_calls=None)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key = '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')\n",
    "# initialisiert langes Gedächtnis\n",
    "ltm_memory = {}\n",
    "\n",
    "def memory_sentinel(message):\n",
    "    # System-Prompt für Memory-Sentinel erstellen\n",
    "    prompt = f\"{message}\\n\\nIs there any important information in this message that should be saved in the long-term memory?\"\n",
    "\n",
    "\n",
    "    # Anfrage an API senden\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Antwort analysieren\n",
    "    answer = response.choices[0].message\n",
    "    print(f\"Memory Sentinel: {answer}\")\n",
    "    return answer == \"yes\"\n",
    "\n",
    "def update_ltm(message, category):\n",
    "    # speichert die Nachricht unter der angegebenen Kategorie in LTM\n",
    "    ltm_memory[category] = message\n",
    "\n",
    "def chat_gpt3(message):\n",
    "    # System-Prompt-Erstellung\n",
    "    ltm = json.dumps(ltm_memory)    # LTM in String umwandeln\n",
    "    prompt = f\"{ltm}\\n{message}\\n\\nWhat should the fitness trainer reply?\"\n",
    "\n",
    "    # Request an API senden\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Antwort zurückgeben\n",
    "    reply = response.choices[0].message\n",
    "    return reply\n",
    "\n",
    "def handle_user_message(message, category):\n",
    "    # prüfen ob die Nachricht für LTM relevant ist\n",
    "    if memory_sentinel(message):\n",
    "        # Nachricht ins LTM aufnehmen\n",
    "        update_ltm(message, category)\n",
    "\n",
    "    # Antwort des Chatbots generieren\n",
    "    reply = chat_gpt3(message)\n",
    "\n",
    "    # Antwort zurückgeben\n",
    "    return reply\n",
    "\n",
    "reply = handle_user_message(\"I can't do exercise due to my knee pain\", \"Physical restrictions\")\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
