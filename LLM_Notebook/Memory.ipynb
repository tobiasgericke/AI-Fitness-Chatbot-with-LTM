{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Sentinel: ChatCompletionMessage(content=\"Yes, the important information that should be saved in long-term memory is the fact that the individual is experiencing knee pain that is preventing them from doing exercise. This information can be useful for future reference in understanding the individual's health and wellness needs.\", role='assistant', function_call=None, tool_calls=None)\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'ChatCompletionMessage' object has no attribute 'lower'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:759\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    758\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 759\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpydantic_extra\u001b[49m\u001b[43m[\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m    760\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mKeyError\u001b[0m: 'lower'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 62\u001b[0m\n\u001b[0;32m     59\u001b[0m     \u001b[38;5;66;03m# Antwort zurückgeben\u001b[39;00m\n\u001b[0;32m     60\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m reply\n\u001b[1;32m---> 62\u001b[0m reply \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_user_message\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mI can\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mt do exercise due to my knee pain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mPhysical restrictions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28mprint\u001b[39m(reply)\n",
      "Cell \u001b[1;32mIn[26], line 52\u001b[0m, in \u001b[0;36mhandle_user_message\u001b[1;34m(message, category)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mhandle_user_message\u001b[39m(message, category):\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;66;03m# prüfen ob die Nachricht für LTM relevant ist\u001b[39;00m\n\u001b[1;32m---> 52\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mmemory_sentinel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     53\u001b[0m         \u001b[38;5;66;03m# Nachricht ins LTM aufnehmen\u001b[39;00m\n\u001b[0;32m     54\u001b[0m         update_ltm(message, category)\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Antwort des Chatbots generieren\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m, in \u001b[0;36mmemory_sentinel\u001b[1;34m(message)\u001b[0m\n\u001b[0;32m     24\u001b[0m answer \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\n\u001b[0;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMemory Sentinel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 26\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43manswer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlower\u001b[49m() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myes\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Tobias\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pydantic\\main.py:761\u001b[0m, in \u001b[0;36mBaseModel.__getattr__\u001b[1;34m(self, item)\u001b[0m\n\u001b[0;32m    759\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m pydantic_extra[item]\n\u001b[0;32m    760\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 761\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mitem\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m    762\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    763\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, item):\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ChatCompletionMessage' object has no attribute 'lower'"
     ]
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "client = OpenAI(api_key = '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')\n",
    "# initialisiert langes Gedächtnis\n",
    "ltm_memory = {}\n",
    "\n",
    "def memory_sentinel(message):\n",
    "    # System-Prompt für Memory-Sentinel erstellen\n",
    "    prompt = f\"{message}\\n\\nIs there any important information in this message that should be saved in the long-term memory?\"\n",
    "\n",
    "\n",
    "    # Anfrage an API senden\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Antwort analysieren\n",
    "    answer = response.choices[0].message\n",
    "    print(f\"Memory Sentinel: {answer}\")\n",
    "    return answer == \"yes\"\n",
    "\n",
    "def update_ltm(message, category):\n",
    "    # speichert die Nachricht unter der angegebenen Kategorie in LTM\n",
    "    ltm_memory[category] = message\n",
    "\n",
    "def chat_gpt3(message):\n",
    "    # System-Prompt-Erstellung\n",
    "    ltm = json.dumps(ltm_memory)    # LTM in String umwandeln\n",
    "    prompt = f\"{ltm}\\n{message}\\n\\nWhat should the fitness trainer reply?\"\n",
    "\n",
    "    # Request an API senden\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"\"},\n",
    "            {\"role\": \"user\", \"content\": prompt},\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Antwort zurückgeben\n",
    "    reply = response.choices[0].message\n",
    "    return reply\n",
    "\n",
    "def handle_user_message(message, category):\n",
    "    # prüfen ob die Nachricht für LTM relevant ist\n",
    "    if memory_sentinel(message):\n",
    "        # Nachricht ins LTM aufnehmen\n",
    "        update_ltm(message, category)\n",
    "\n",
    "    # Antwort des Chatbots generieren\n",
    "    reply = chat_gpt3(message)\n",
    "\n",
    "    # Antwort zurückgeben\n",
    "    return reply\n",
    "\n",
    "reply = handle_user_message(\"I can't do exercise due to my knee pain\", \"Physical restrictions\")\n",
    "print(reply)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
